# -*- coding: utf-8 -*-
"""NLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PzVuGmrpxEjVLS_JhyD8T4Vei_h8d2bI
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
from collections import Counter
import nltk
from nltk.corpus import stopwords
nltk.download('stopwords')
nltk.download('punkt')

import warnings
import logging

warnings.filterwarnings("ignore")
logging.getLogger('nltk').setLevel(logging.CRITICAL)  # Suppress NLTK logs

# Load TSV file
data = pd.read_csv('reviews.tsv', sep='\t')

# Use the translation.reviewText column for non-English rows
data['reviewText'] = np.where(data['languageCode'] != 'en-US', data['translation.reviewText'], data['reviewText'])

# Calculate the average rating for each product
average_ratings = data.groupby('productId')['ratingValue'].mean().reset_index(name='average_rating')

# Calculate the total sales for each product
total_sales = data.groupby('productId').size().reset_index(name='total_sales')

# Merge the average ratings and total sales data
product_data = average_ratings.merge(total_sales, on='productId')

# Calculate the popularity score for each product
product_data['popularity_score'] = product_data['average_rating'] * product_data['total_sales']

# Sort the products by popularity score
sorted_products = product_data.sort_values('popularity_score', ascending=False)

# Extract the most popular product based on the popularity score
most_popular_product = sorted_products.iloc[0]['productId']
print(most_popular_product)
# Extract the reviews for the most popular product
most_popular_product_reviews = data[data['productId'] == most_popular_product]

# Tokenize review text
def tokenize(text):
    tokens = nltk.word_tokenize(text.lower())
    return [word for word in tokens if word.isalnum()]

# Process the review text
most_popular_product_reviews['tokens'] = most_popular_product_reviews['reviewText'].apply(tokenize)

# Collect all tokens into a single list
all_tokens = []
for tokens in most_popular_product_reviews['tokens']:
    all_tokens.extend(tokens)

# Remove stopwords and words "mask" and "masks"
stop_words = set(stopwords.words('english'))
stop_words.add('mask')
stop_words.add('masks')
filtered_tokens = [word for word in all_tokens if word not in stop_words]

# Count word frequencies
word_frequencies = Counter(filtered_tokens)

# Get top reasons why consumers like the most popular face masks
top_reasons = word_frequencies.most_common(10)
print("\nTop reasons why consumers like the most popular face masks:")
for reason, count in top_reasons:
    print(f"{reason}: {count}")

from PIL import Image, ImageOps
import numpy as np

def generate_wordcloud(words, title, mask_path=None):
    # Load the mask image, convert it to binary, and then to a NumPy array
    if mask_path:
        mask_image = Image.open(mask_path).convert("L")  # Convert the image to grayscale
        threshold = 128  # Set a threshold value to create a binary image
        mask_image = mask_image.point(lambda p: p > threshold and 255)  # Apply the threshold
        mask_array = np.array(mask_image)
    else:
        mask_array = None

    wordcloud = WordCloud(
        width=400, height=400,
        background_color='black',  # Set background
        mode='RGBA',  # Set mode to RGBA for transparent background
        min_font_size=10,
        max_words=100,
        collocations=True,  # Enable collocations for a dynamic layout
        normalize_plurals=False,  # This will ensure the word cloud treats singular and plural forms separately
        prefer_horizontal=0.8,  # Set horizontal word preference to 80%
        colormap='viridis',  # Change the color scheme
        mask=mask_array,  # Add the mask array
    ).generate_from_frequencies(words)

    plt.figure(figsize=(8, 8), facecolor=None)
    plt.imshow(wordcloud, interpolation="bilinear")  # Use bilinear interpolation for smoother rendering
    plt.axis("off")
    plt.tight_layout(pad=0)
    plt.title(title, fontsize=20)
    plt.show()

# Create and display the word cloud
generate_wordcloud(word_frequencies, "Top Reasons", "mask.png")

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

def find_sentences_containing_word(word, reviews, num_examples=3):
    sentences = []
    for review in reviews:
        sentences.extend(nltk.sent_tokenize(review))

    # Calculate the cosine similarity between the word and the sentences
    vectorizer = TfidfVectorizer(stop_words='english')

    # Create a temporary sentence containing the word to prevent it from being treated as a stop word
    temp_sentence = f"This is a temporary sentence containing the word {word}."

    word_vector = vectorizer.fit_transform([temp_sentence])
    sentence_vectors = vectorizer.transform(sentences)
    similarity_scores = cosine_similarity(word_vector, sentence_vectors).flatten()

    # Sort sentences by similarity score and get the top num_examples sentences
    sorted_indices = similarity_scores.argsort()[::-1]
    relevant_sentences = [sentences[index] for index in sorted_indices[:num_examples]]

    return relevant_sentences



# Get example sentences for each top reason
def get_example_sentences(top_reasons, reviews, num_examples=3):
    example_sentences = {}
    for reason, _ in top_reasons:
        sentences = find_sentences_containing_word(reason, reviews)
        example_sentences[reason] = sentences[:num_examples]
    return example_sentences

# Get the top reasons with example sentences
top_reasons_with_examples = get_example_sentences(top_reasons, most_popular_product_reviews['reviewText'])

# Print the top reasons with example sentences
print("Top reasons why consumers like the most popular face masks with example sentences:")
for reason, examples in top_reasons_with_examples.items():
    print(f"\n{reason}:")
    for example in examples:
        print(f"- {example}")